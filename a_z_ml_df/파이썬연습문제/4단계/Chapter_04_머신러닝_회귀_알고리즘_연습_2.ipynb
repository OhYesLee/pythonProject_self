{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Chapter 04. 머신러닝 회귀 알고리즘 연습 2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn_bPjW10qHz"
      },
      "source": [
        "# Chapter 04. 머신러닝 회귀 문제 연습하기 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx-hyOnbRdm_"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR5XfHWy0qIi"
      },
      "source": [
        "## 실습 가이드\n",
        "1. 데이터를 다운로드하여 Colab에 불러옵니다.\n",
        "> 다운로드한 데이터의 위치는 **Colab Notebooks/data/** 로 통일합니다.\n",
        "\n",
        "2. 필요한 라이브러리는 모두 코드로 작성되어 있습니다.\n",
        "3. 코드는 위에서부터 아래로 순서대로 실행합니다.\n",
        "4. 전체 문제 구성은 좌측 첫 번째 아이콘을 통해 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arCV66fJ0qIk"
      },
      "source": [
        "### <b> 데이터의 속성</b>\n",
        "**시작 전에** 원본 Kaggle 페이지에서 상세한 데이터에 대한 설명을 확인하세요 !\n",
        "\n",
        "Reference : https://www.kaggle.com/c/zillow-prize-1/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlsQsuiB0qIm"
      },
      "source": [
        "### <b>학습목표</b>\n",
        "- 1) Regression 모델의 이해\n",
        "- 2) 학습했던 다양한 머신러닝 회귀모델의 이해\n",
        "- 3) 회귀를 위한 데이터 전처리 방법에 대한 이해\n",
        "- 4) feature engineering에 대한 이해\n",
        "- 5) 평가결과를 바탕으로 모델을 개선하는 방법 습득"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3cbNzXr0qIn"
      },
      "source": [
        "- 출제자: 김용담 강사"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjX8li2Aw95P"
      },
      "source": [
        "## ++ 추가 설명 ++\n",
        "\n",
        "원래 Kaggle 대회의 목적은 2016, 2017년 데이터를 통해서 2017년 10, 11월 집값을 예측하는 문제를 풉니다.\n",
        "\n",
        "저희는 실습의 편의성을 위해서 문제를 간소화하여 2016년도 데이터를 가지고 2016년 데이터 중에서 2016년 1월부터 9월까지의 데이터는 학습 데이터로 사용하고, 10월부터 12월까지의 3개월 데이를 테스트 데이터로 사용하는 문제로 변환합니다.\n",
        "\n",
        "그렇기 때문에, 데이터 중에서 2016년 데이터만 사용합니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0CtisIz0qIo"
      },
      "source": [
        "## Step 1. 예측할 데이터 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2MLQ8Ff0qIp"
      },
      "source": [
        "### 문제 01. 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEUiebcx0qIq"
      },
      "source": [
        "# 분석에 필요한 라이브러리를 불러옵니다\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRCsZ6CBEBM5"
      },
      "source": [
        "base_path = '/content/drive/MyDrive/Colab Notebooks/data/zillow-prize-1'\n",
        "train = \n",
        "properties = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cupV8lpw0qIr"
      },
      "source": [
        "### 문제 02. 데이터 미리보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrtfD32hD-yz"
      },
      "source": [
        "# 데이터 크기 확인\n",
        "\n",
        "\n",
        "# 데이터 일부 확인\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZMNz6Es0qIs"
      },
      "source": [
        "### 문제 03. 데이터 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWLusfet0qIt"
      },
      "source": [
        "# train 데이터에서 결측치가 있는 column 확인하기\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqYtcDqX0qIw"
      },
      "source": [
        "# test도 확인\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB0Eo_-D0qIx"
      },
      "source": [
        "## Step 2. Data Preprocessing\n",
        "\n",
        "- 학습에 필요한 데이터를 만들기 위해서, train 데이터와 properties 데이터를 합칩니다.\n",
        "\n",
        "- 합친 다음, 결측치가 존재한다면 결측치를 처리합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL3ndm06e7S1"
      },
      "source": [
        "### 문제 04. train data와 properties data 합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aFU8iCqfkyp"
      },
      "source": [
        "# train data와 properties data에 공통으로 있는 column을 기준으로 합칩니다.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJc3-Mz8gSR6"
      },
      "source": [
        "### 문제 05. 합친 data에서 결측치가 있는 데이터 뽑기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N1S5Ux-iaqz"
      },
      "source": [
        "# 결측치가 있는 데이터를 뽑습니다.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOJdhhAFfL_S"
      },
      "source": [
        "## 결측치 채우기\n",
        "\n",
        "- 결측치가 포함된 row가 모든 row이므로, 특정 column에 결측치가 많이 포함되어 있는 경우입니다.\n",
        "\n",
        "- 결측치가 많이 포함된 column들을 먼저 찾고, 해당 column들을 어떻게 처리할지 결정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2azgZATtnKb8"
      },
      "source": [
        "### 문제 06. 결측치 패턴 파악하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5nfgaF2j2fz"
      },
      "source": [
        "# 결측치 패턴 확인하기\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No6tNT3Pmjr_"
      },
      "source": [
        "- basementsqft, buildingclasstypeid 같은 column들에 값이 거의 없습니다.\n",
        "\n",
        "- 90% 이상 결측인 column들을 찾아서 제거합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4oZ1yV-kNgM"
      },
      "source": [
        "### 문제 07. 90% 이상 결측인 column들 제거하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_EZhH_dkNxm"
      },
      "source": [
        "# 90% 이상 결측인 column들 뽑기\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km4KDZ-Xvmhk"
      },
      "source": [
        "# 90% 이상인 column들을 제거합니다.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRCLeS3VlARY"
      },
      "source": [
        "### 문제 08. 결측이 존재하는 나머지 column들 찾기\n",
        "\n",
        "- 나머지 결측을 포함하고 있는 column들이 여전히 많습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdvdyrZAkl6M"
      },
      "source": [
        "# 여전히 결측치를 포함하고 있는 column들 찾기\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjnYBx_jn1Qo"
      },
      "source": [
        "### 문제 09. 결측치 채우기 1\n",
        "\n",
        "- 나머지 column들중 continuous한 numeric feature들은 평균값으로 채워줍니다.\n",
        "\n",
        "- column들중 매우 높은 cardinality를 가지고 있는 column들은 continuous할 가능성이 높습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c49lEF_pr1Zs"
      },
      "source": [
        "# continuous feature를 찾기 위해서, column별로 cardinality를 구합니다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "missing_df = \n",
        "missing_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g45sHFIoQ21f"
      },
      "source": [
        "- cardinality가 눈에 띄게 높은 structuretaxvaluedollarcnt, taxvaluedollarcnt, landtaxvaluedollarcnt, taxamount, censustractandblock column은 평균값으로 채웁니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf_c_ytHs7q0"
      },
      "source": [
        "# # continuous column 지정\n",
        "continuous = \n",
        "continuous"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7o5EkGjtJm0"
      },
      "source": [
        "### 문제 10. 결측치 채우기 2\n",
        "\n",
        "- discrete한 numeric feature들은 최빈값으로 결측치를 채워줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdJrA5QQ6Fm_"
      },
      "source": [
        "# \bdiscrete feature를 찾기 위해서, column별로 cardinality를 구합니다.\n",
        "missing_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8O3i-dpRg1F"
      },
      "source": [
        "- 앞에서 찾은 5개의 column을 제외한 나머지 column들을 discrete feature로 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7VhUDCtn0f9"
      },
      "source": [
        "# continuous column 지정\n",
        "discretes = \n",
        "discretes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5XVN43Uz-dt"
      },
      "source": [
        "### 문제 11. 결측치 채우기 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMTdk2Y5z-Vx"
      },
      "source": [
        "# continuous feature는 평균값으로, discrete feature는 최빈값으로 결측치를 채웁니다.\n",
        "\n",
        "modes =  # 최빈값\n",
        "means =  # 평균\n",
        "\n",
        "for column in discretes:\n",
        "    \n",
        "    \n",
        "for column in continuous:\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M5a2kv0z6J9"
      },
      "source": [
        "# 결측치 확인\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4jRExCetYGb"
      },
      "source": [
        "## Step 3. Feature Engineering\n",
        "\n",
        "- 분석에 사용할 feature들을 만들고, 학습을 위한 데이터를 준비하는 단계입니다.\n",
        "\n",
        "- 모든 categorical feature들을 변환하여 데이터를 feature vector로 만들어봅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRnKXsre1SUr"
      },
      "source": [
        "### 문제 12. date_time을 시간정보로 변환하기\n",
        "\n",
        "- date_time feature로 사용하기 위해서 시간 정보로 변환해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJriF5wM1RlM"
      },
      "source": [
        "# datetime data type으로 변환하기\n",
        "data.transactiondate = \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVbiZ6d23Ja3"
      },
      "source": [
        "### 문제 13. 필요없는 feature 제거하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hutDOGQe8fKC"
      },
      "source": [
        "# 분석에 사용할 수 없는 두 개의 object type column은 제거합니다.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L99yG6eh-wA_"
      },
      "source": [
        "## 문제 14. train-test 분리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6-499yW_DRU"
      },
      "source": [
        "# 2016년 10월 전후로 데이터를 나눕니다.\n",
        "X_train_2016 = \n",
        "X_test_2016 = \n",
        "print(X_train_2016.shape, X_test_2016.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9Z6Fxpsnv2p"
      },
      "source": [
        "### 문제 15. X, y 분리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Iko3gZbAUrO"
      },
      "source": [
        "# 2016-10-01 이전 데이터 X, y 분리\n",
        "X_train = \n",
        "y_train = \n",
        "\n",
        "# 2016-10-01 이후 데이터 X, y 분리\n",
        "X_test = \n",
        "y_test = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYrc0IwXGT2q"
      },
      "source": [
        "### 문제 16. feature scaling\n",
        "\n",
        "- tree method 계열은 scaling이 필요하지 않지만, linear regression 계열은 scale에 굉장히 민감하기 때문에, 사전에 scaling을 해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_T-BCbe0qI3"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = \n",
        "X_train_scaled = \n",
        "X_test_scaled = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fTacCwrEVBR"
      },
      "source": [
        "# 스케일 조정된 X_train 데이터 확인하기\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyrluBHm0qI4"
      },
      "source": [
        "### 참고: scikit-learn에서 제공하는 피처 스케일러(scaler)\n",
        "\n",
        "- `StandardScaler`: 기본 스케일, 각 피처의 평균을 0, 표준편차를 1로 변환\n",
        "- `RobustScaler`: 위와 유사하지만 평균 대신 중간값(median)과 일분위, 삼분위값(quartile)을 사용하여 이상치 영향을 최소화\n",
        "- `MinMaxScaler`: 모든 피처의 최대치와 최소치가 각각 1, 0이 되도록 스케일 조정\n",
        "- `Normalizer`: 피처(컬럼)이 아니라 row마다 정규화되며, 유클리드 거리가 1이 되도록 데이터를 조정하여 빠르게 학습할 수 있게 함\n",
        "\n",
        "<p> 스케일 조정을 하는 이유는 데이터의 값이 너무 크거나 작을 때 학습이 제대로 되지 않을 수도 있기 때문입니다. 또한 스케일의 영향이 절대적인 분류기(예: knn과 같은 거리기반 알고리즘)의 경우, 스케일 조정을 필수적으로 검토해야 합니다.\n",
        "    \n",
        "<p> 반면 어떤 항목은 원본 데이터의 분포를 유지하는 것이 나을 수도 있습니다. 예를 들어, 데이터가 거의 한 곳에 집중되어 있는 feature를 표준화시켜 분포를 같게 만들었을 때, 작은 단위의 변화가 큰 차이를 나타내는 것처럼 학습될 수도 있습니다. 또한 스케일의 영향을 크게 받지 않는 분류기(예: 트리 기반 앙상블 알고리즘)를 사용할 경우에도 성능이 준수하게 나오거나 과대적합(overfitting)의 우려가 적다면 생략할 수도 있습니다.\n",
        "    \n",
        "<p> 스케일 조정시 유의해야할 점은 원본 데이터의 의미를 잃어버릴 수 있다는 것입니다. 최종적으로 답을 구하는 것이 목적이 아니라 모델의 해석이나 향후 다른 데이터셋으로의 응용이 더 중요할 때 원 피처에 대한 설명력을 잃어버린다면 모델 개선이 어려울 수도 있습니다. 이 점을 함께 고려하시면 좋겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSA1NIBa0qI6"
      },
      "source": [
        "## Step 4. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1hHD5bjCb8y"
      },
      "source": [
        "- 공부한 각 머신러닝 회귀 모델들을 돌려보고, 성능을 평가합니다.\n",
        "\n",
        "- 아래 모델들이 그 대상에 해당합니다.\n",
        "\n",
        "- Linear Regression / Ridge / Lasso / Random Forest / SVR / xgboost / lightgbm / catboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14kriJ_j0qI6"
      },
      "source": [
        "### 문제 17. Linear Regression 모델 돌려보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVP2tN1U0qI7"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "linear_reg = \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIH9m2RF0qI7"
      },
      "source": [
        "### 문제 18. Linear Regression 모델의 MAE 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "teFIrxQA0qI8"
      },
      "source": [
        "pred = linear_reg.predict(X_train_scaled)\n",
        "linear_reg_score = mean_absolute_error(y_train, pred)\n",
        "\n",
        "print('Linear Regression MAE: {0:0.4f}'.format(linear_reg_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4UkbF6yEte8"
      },
      "source": [
        "### 문제 19. Lasso 모델 돌려보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxIdMw4PEtqG"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso = \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UFi6fqWE9qQ"
      },
      "source": [
        "### 문제 20. Lasso 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIeh3qnxFA8f"
      },
      "source": [
        "pred = \n",
        "lasso_score = mean_absolute_error(y_train, pred)\n",
        "\n",
        "print('Lasso MAE: {0:0.4f}'.format(lasso_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YKA9pSIEI7G"
      },
      "source": [
        "### 문제 21. Random Forest 모델 돌려보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIJ8FkkJEHI4"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp7fM5KvUGHE"
      },
      "source": [
        "pred = \n",
        "rf_score = mean_absolute_error(y_train, pred)\n",
        "print('Random Forest MAE : {0:0.4f}'.format(rf_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9WojjlOGe_K"
      },
      "source": [
        "### 문제 22. Support Vector Machine 모델 돌려보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGh_QbGPGfVQ"
      },
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "# 데이터가 10000개 이상일 때는 LinearSVR을 추천합니다.\n",
        "svr = \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfV7NIdYGfPF"
      },
      "source": [
        "pred = \n",
        "svm_score = mean_absolute_error(y_train, pred)\n",
        "print('Support Vector Machine MAE: {0:0.4f}'.format(svm_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wknluIW_0qJE"
      },
      "source": [
        "### 문제 23. XGBoost 모델 돌려보기\n",
        "\n",
        "- xgboost의 구현체가 많지만, 여기서는 sklearn version을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig7tGMy4Hy2f"
      },
      "source": [
        "from xgboost.sklearn import XGBRegressor\n",
        "\n",
        "xgb = \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW5sYu6MICW5"
      },
      "source": [
        "pred = \n",
        "xgb_score = mean_absolute_error(y_train, pred)\n",
        "print('XGBoost MAE : {0:0.4f}'.format(xgb_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XZkWQ2E0qJG"
      },
      "source": [
        "### 문제 24. Light GBM 모델 돌려보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zV3jXvMIIM0"
      },
      "source": [
        "from lightgbm.sklearn import LGBMRegressor\n",
        "\n",
        "lgb = \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAyGd8_nIYer"
      },
      "source": [
        "pred = \n",
        "lgb_score = mean_absolute_error(y_train, pred)\n",
        "print('LightGBM MAE: {0:0.4f}'.format(lgb_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_5l_T2-0qJE"
      },
      "source": [
        "### 참고 : 부스팅(Boosting) 모델 개요\n",
        "\n",
        "\n",
        "- 부스팅은 여러 트리의 적합 결과를 합하는 앙상블 알고리즘의 하나로, 이 때 sequential의 개념이 추가되어 있습니다. 즉 연속적인 weak learner, 바로 직전 weak learner의 error를 반영한 현재 weak learner를 잡겠다는 것입니다. 이 아이디어는 Gradient Boosting Model(GBM)에서 loss를 계속 줄이는 방향으로 weak learner를 잡는다는 개념으로 확장됩니다.\n",
        "\n",
        "![boost](https://pluralsight2.imgix.net/guides/81232a78-2e99-4ccc-ba8e-8cd873625fdf_2.jpg)\n",
        "\n",
        "\n",
        "- 부스팅 계열 모델은 XGBoost, LightGBM, CatBoost 등이 있습니다.\n",
        "\n",
        "\n",
        "- 더 자세한 내용은 다음 Step에서 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F15Q5DnCI0BJ"
      },
      "source": [
        "### 문제 25. Test prediction\n",
        "\n",
        "- 학습한 모델을 기반하여 test 데이터를 평가합니다. 그 예측값이 대회 제출이 되는 기준입니다.\n",
        "\n",
        "\n",
        "- 실제 현업에서는 서비스에 들어가는 기술을 test 데이터로 평가합니다. 마치 유저가 들어온 것처럼요.\n",
        "\n",
        "- 이번엔 데이터로 2016년도 데이터만 사용했기 때문에, 최종 데이터 template이 아닌 예측한 데이터만 정리합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erlbgiieIzrT"
      },
      "source": [
        "# 모델을 하나 정해서, test data에 대한 inference를 진행합니다.\n",
        "final = \n",
        "final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghRjOQtrKToF"
      },
      "source": [
        "# 결과 파일 정리\n",
        "result = \n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUz80L2m0qJI"
      },
      "source": [
        "### 문제 26. 최종 성능 정리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "qp15ChOf0qJJ"
      },
      "source": [
        "print('MAE Comparisons for Various Regression Models\\n')\n",
        "print('linear_reg_score:', )\n",
        "print('lasso_score   :', )\n",
        "print('rf_score   :', )\n",
        "print('svm_score   :', )\n",
        "print('xgb_score   :', )\n",
        "print('lgb_score   :', )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W05Y19ceIxQe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}