{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Chapter 04. 머신러닝 분류 알고리즘 연습 2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn_bPjW10qHz"
      },
      "source": [
        "# Chapter 04. 머신러닝 분류 문제 연습하기 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx-hyOnbRdm_"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR5XfHWy0qIi"
      },
      "source": [
        "## 실습 가이드\n",
        "1. 데이터를 다운로드하여 Colab에 불러옵니다.\n",
        "> 다운로드한 데이터의 위치는 **Colab Notebooks/data/** 로 통일합니다.\n",
        "\n",
        "2. 필요한 라이브러리는 모두 코드로 작성되어 있습니다.\n",
        "3. 코드는 위에서부터 아래로 순서대로 실행합니다.\n",
        "4. 전체 문제 구성은 좌측 첫 번째 아이콘을 통해 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arCV66fJ0qIk"
      },
      "source": [
        "### <b> 데이터의 속성</b>\n",
        "**시작 전에** 원본 데이콘 페이지에서 상세한 데이터에 대한 설명을 확인하세요 !\n",
        "\n",
        "Reference : https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlsQsuiB0qIm"
      },
      "source": [
        "### <b>학습목표</b>\n",
        "- 1) Binary Classification 모델의 이해\n",
        "- 2) 학습했던 다양한 머신러닝 분류모델의 이해\n",
        "- 3) 분류를 위한 데이터 전처리 방법에 대한 이해\n",
        "- 4) feature engineering에 대한 이해\n",
        "- 5) 평가결과를 바탕으로 모델을 개선하는 방법 습득"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3cbNzXr0qIn"
      },
      "source": [
        "- 출제자: 김용담 강사"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0CtisIz0qIo"
      },
      "source": [
        "## Step 1. 예측할 데이터 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2MLQ8Ff0qIp"
      },
      "source": [
        "### 문제 01. 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEUiebcx0qIq"
      },
      "source": [
        "# 분석에 필요한 라이브러리를 불러옵니다\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRCsZ6CBEBM5"
      },
      "source": [
        "# 데이터 경로를 찾습니다. 원본 데이터를 그대로 구글드라이브에 업로드를 하세요.\n",
        "data = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cupV8lpw0qIr"
      },
      "source": [
        "### 문제 02. 데이터 미리보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrtfD32hD-yz"
      },
      "source": [
        "# 데이터 크기 확인\n",
        "\n",
        "\n",
        "# 데이터 일부 확인\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZMNz6Es0qIs"
      },
      "source": [
        "### 문제 03. 데이터 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWLusfet0qIt"
      },
      "source": [
        "# 데이터에서 결측치가 있는 column 확인하기\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB0Eo_-D0qIx"
      },
      "source": [
        "## Step 2. Data Preprocessing\n",
        "\n",
        "- 이번 데이터는 결측치가 없습니다.\n",
        "\n",
        "- 학습을 위해서 column들을 정리하고, train-test split을 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL3ndm06e7S1"
      },
      "source": [
        "### 문제 04. 데이터 feature matrix(X)와 target vector(y) 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4kMuoAUezL7"
      },
      "source": [
        "# data에서 X, y를 정의합니다.\n",
        "X = \n",
        "y = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJc3-Mz8gSR6"
      },
      "source": [
        "### 문제 05. train test 데이터 나누기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N1S5Ux-iaqz"
      },
      "source": [
        "# 학습의 평가를 위해서 데이터의 일부를 test data로 나누고, 나머지 데이터를 학습에 사용합니다.\n",
        "\n",
        "\n",
        "# 25%를 test data로 사용합니다.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATBq8RIHiaol"
      },
      "source": [
        "# 잘 나누어졌는지 크기를 확인합니다.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4jRExCetYGb"
      },
      "source": [
        "## Step 3. Feature Engineering\n",
        "\n",
        "- 분석에 사용할 feature들을 만들고, 학습을 위한 데이터를 준비하는 단계입니다.\n",
        "\n",
        "- 분석할 데이터들의 scale을 통일시켜줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxEweQuP0qI2"
      },
      "source": [
        "### 문제 06. feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_T-BCbe0qI3"
      },
      "source": [
        "# StandardScaler로 변환하기\n",
        "\n",
        "\n",
        "\n",
        "X_train_standard = \n",
        "X_test_standard = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fTacCwrEVBR"
      },
      "source": [
        "# 스케일 조정된 X_train 데이터 확인하기\n",
        "X_train_standard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UEjbhkajTe9"
      },
      "source": [
        "### 문제 07. feature scaling 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh4lRCAdjMLs"
      },
      "source": [
        "# feature scaling의 성능 비교를 위해 RobustScaler도 사용해봅니다.\n",
        "\n",
        "\n",
        "\n",
        "X_train_robust = \n",
        "X_test_robust = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciwVfj7Vjn96"
      },
      "source": [
        "# 변경된 값 확인\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyrluBHm0qI4"
      },
      "source": [
        "### 참고: scikit-learn에서 제공하는 피처 스케일러(scaler)\n",
        "\n",
        "- `StandardScaler`: 기본 스케일, 각 피처의 평균을 0, 표준편차를 1로 변환\n",
        "- `RobustScaler`: 위와 유사하지만 평균 대신 중간값(median)과 일분위, 삼분위값(quartile)을 사용하여 이상치 영향을 최소화\n",
        "- `MinMaxScaler`: 모든 피처의 최대치와 최소치가 각각 1, 0이 되도록 스케일 조정\n",
        "- `Normalizer`: 피처(컬럼)이 아니라 row마다 정규화되며, 유클리드 거리가 1이 되도록 데이터를 조정하여 빠르게 학습할 수 있게 함\n",
        "\n",
        "<p> 스케일 조정을 하는 이유는 데이터의 값이 너무 크거나 작을 때 학습이 제대로 되지 않을 수도 있기 때문입니다. 또한 스케일의 영향이 절대적인 분류기(예: knn과 같은 거리기반 알고리즘)의 경우, 스케일 조정을 필수적으로 검토해야 합니다.\n",
        "    \n",
        "<p> 반면 어떤 항목은 원본 데이터의 분포를 유지하는 것이 나을 수도 있습니다. 예를 들어, 데이터가 거의 한 곳에 집중되어 있는 feature를 표준화시켜 분포를 같게 만들었을 때, 작은 단위의 변화가 큰 차이를 나타내는 것처럼 학습될 수도 있습니다. 또한 스케일의 영향을 크게 받지 않는 분류기(예: 트리 기반 앙상블 알고리즘)를 사용할 경우에도 성능이 준수하게 나오거나 과대적합(overfitting)의 우려가 적다면 생략할 수도 있습니다.\n",
        "    \n",
        "<p> 스케일 조정시 유의해야할 점은 원본 데이터의 의미를 잃어버릴 수 있다는 것입니다. 최종적으로 답을 구하는 것이 목적이 아니라 모델의 해석이나 향후 다른 데이터셋으로의 응용이 더 중요할 때 원 피처에 대한 설명력을 잃어버린다면 모델 개선이 어려울 수도 있습니다. 이 점을 함께 고려하시면 좋겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSA1NIBa0qI6"
      },
      "source": [
        "## Step 4. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1hHD5bjCb8y"
      },
      "source": [
        "- 공부한 각 머신러닝 분류 모델들을 돌려보고, 성능을 평가합니다.\n",
        "\n",
        "- 아래 모델들이 그 대상에 해당합니다.\n",
        "\n",
        "- Logistic Regression / Naive Bayes / Decision Tree / Random Forest / KNN / SVM / xgboost / lightgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14kriJ_j0qI6"
      },
      "source": [
        "### 문제 08. Logistic Regression 모델 돌려보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVP2tN1U0qI7"
      },
      "source": [
        "# Logistic Regression으로 학습\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIH9m2RF0qI7"
      },
      "source": [
        "### 문제 09. Logistic Regression 모델의 정확도 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "teFIrxQA0qI8"
      },
      "source": [
        "# 학습 모델의 정확도 평가\n",
        "\n",
        "logreg_score = \n",
        "\n",
        "print('Logistic Regression accuracy score: {0:0.4f}'.format(logreg_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4UkbF6yEte8"
      },
      "source": [
        "### 문제 10. Naive Bayes 모델 돌려보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxIdMw4PEtqG"
      },
      "source": [
        "# NB 모델중에 하나를 불러와서 학습\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UFi6fqWE9qQ"
      },
      "source": [
        "### 문제 11. Naive Bayes 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIeh3qnxFA8f"
      },
      "source": [
        "# 학습 모델의 정확도 평가\n",
        "nb_score = \n",
        "\n",
        "print('Naive Bayes accuracy score: {0:0.4f}'.format(nb_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INCXInIe0qJA"
      },
      "source": [
        "### 문제 12. Random Forest 모델 돌려보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYjynAEf0qJB"
      },
      "source": [
        "# RandomForestClassifier 모델 학습\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp7fM5KvUGHE"
      },
      "source": [
        "# 학습 모델의 정확도 평가\n",
        "\n",
        "rf_score = \n",
        "print('Random Forest Model accuracy score : {0:0.4f}'.format(rf_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RFhNWs0FUL2"
      },
      "source": [
        "### 문제 13. KNN Classification 모델 돌려보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKzTiDzKFTpb"
      },
      "source": [
        "# KNNClassifier로 모델 학습\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJlsw13RGYUo"
      },
      "source": [
        "# 학습 모델의 정확도 평가\n",
        "knn_score = \n",
        "print('KNN classification accuracy score : {0:0.4f}'.format(knn_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9WojjlOGe_K"
      },
      "source": [
        "### 문제 14. Support Vector Machine 모델 돌려보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGh_QbGPGfVQ"
      },
      "source": [
        "# Support Vector Classifier로 모델 학습\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfV7NIdYGfPF"
      },
      "source": [
        "# 학습 모델의 정확도 평가\n",
        "\n",
        "svm_score = \n",
        "print('Support Vector Machine accuracy score : {0:0.4f}'.format(svm_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wknluIW_0qJE"
      },
      "source": [
        "### 문제 15. XGBoost 모델 돌려보기\n",
        "\n",
        "- xgboost의 구현체가 많지만, 여기서는 sklearn version을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig7tGMy4Hy2f"
      },
      "source": [
        "# XGBoost 모델 학습\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qASAE5ow0qJG"
      },
      "source": [
        "### 문제 16. XGBoost 모델의 분류결과 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW5sYu6MICW5"
      },
      "source": [
        "# 학습 모델의 정확도 평가\n",
        "\n",
        "xgb_score = \n",
        "print('XGBoost accuracy score : {0:0.4f}'.format(xgb_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XZkWQ2E0qJG"
      },
      "source": [
        "### 문제 17. Light GBM 모델 돌려보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zV3jXvMIIM0"
      },
      "source": [
        "# LightGBM 모델 학습\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3YwlN_x0qJH"
      },
      "source": [
        "### 문제 18. Light GBM 분류결과 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAyGd8_nIYer"
      },
      "source": [
        "# 학습 모델의 정확도 평가\n",
        "\n",
        "lgb_score = \n",
        "print('XGBoost accuracy score : {0:0.4f}'.format(lgb_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_5l_T2-0qJE"
      },
      "source": [
        "### 참고 : 부스팅(Boosting) 모델 개요\n",
        "\n",
        "\n",
        "- 부스팅은 여러 트리의 적합 결과를 합하는 앙상블 알고리즘의 하나로, 이 때 sequential의 개념이 추가되어 있습니다. 즉 연속적인 weak learner, 바로 직전 weak learner의 error를 반영한 현재 weak learner를 잡겠다는 것입니다. 이 아이디어는 Gradient Boosting Model(GBM)에서 loss를 계속 줄이는 방향으로 weak learner를 잡는다는 개념으로 확장됩니다.\n",
        "\n",
        "![boost](https://pluralsight2.imgix.net/guides/81232a78-2e99-4ccc-ba8e-8cd873625fdf_2.jpg)\n",
        "\n",
        "\n",
        "- 부스팅 계열 모델은 XGBoost, LightGBM, CatBoost 등이 있습니다.\n",
        "\n",
        "\n",
        "- 더 자세한 내용은 다음 Step에서 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAkna1SEmnu-"
      },
      "source": [
        "### 문제 19. 성능이 가장 좋은 모델 3개를 뽑아서 RobustScaler로 성능 비교하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ENapwGHmr1h"
      },
      "source": [
        "# RandomForest, XGBoost, LightGBM 3개의 모델로 비교 실험을 수행합니다.\n",
        "\n",
        "\n",
        "\n",
        "print('RandomForest accuracy score : {0:0.4f}'.format())\n",
        "print('XGBoost accuracy score : {0:0.4f}'.format())\n",
        "print('LightGBM accuracy score : {0:0.4f}'.format())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F15Q5DnCI0BJ"
      },
      "source": [
        "### 문제 20. Test prediction\n",
        "\n",
        "- 학습한 모델을 기반하여 test 데이터를 평가합니다. \n",
        "\n",
        "\n",
        "- 실제 현업에서는 서비스에 들어가는 기술을 test 데이터로 평가합니다. 마치 유저가 들어온 것처럼요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erlbgiieIzrT"
      },
      "source": [
        "# 모델을 하나 정해서, test data에 대한 inference를 진행합니다.\n",
        "final = \n",
        "final2 = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY1x0pXXolph"
      },
      "source": [
        "# 성능 테스트\n",
        "print('xxx model with Standard Scaler accuracy score : {0:0.4f}'.format(accuracy_score(y_test, final)))\n",
        "print('xxx model with Robust Scaler accuracy score : {0:0.4f}'.format(accuracy_score(y_test, final2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsTZOzZmJXuV"
      },
      "source": [
        "# 결과 파일 생성\n",
        "result = pd.DataFrame({\"ID\":X_test.index, \"target\":final}).set_index(\"ID\").sort_index()\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUz80L2m0qJI"
      },
      "source": [
        "### 문제 21. 최종 성능 정리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "qp15ChOf0qJJ"
      },
      "source": [
        "print('Accuracy Comparisons for Binary Models\\n')\n",
        "\n",
        "print('logreg_score:', '{0:0.5f}'.format())\n",
        "print('nb_score:', '{0:0.5f}'.format())\n",
        "print('rf_score   :', '{0:0.5f}'.format())\n",
        "print('knn_score   :', '{0:0.5f}'.format())\n",
        "print('svm_score   :', '{0:0.5f}'.format())\n",
        "print('xgb_score   :', '{0:0.5f}'.format())\n",
        "print('lgb_score   :', '{0:0.5f}'.format())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}